{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12a2d745-ab7b-4a16-a7fd-5330a7e775e1",
   "metadata": {},
   "source": [
    "# CNN with cats and dogs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dcc558-d46f-4d4e-96bf-95ebee59c547",
   "metadata": {},
   "source": [
    "pip install jupyterlab-widgets\n",
    "pip install kagglehub\n",
    "then reboot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143630c1-4ba4-42e2-8bba-2881eeb14903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import kagglehub\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Check if you're in the correct virtual environment\n",
    "print(f\"Using Python executable: {sys.executable}\")\n",
    "\n",
    "# Suppress TensorFlow informational messages for cleaner output\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc87f8fa-362e-49b2-a783-82a7d00b76f4",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f043e3a8-9302-4a58-9ed0-f80267ef27b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Define the destination folder name\n",
    "destination_folder = \"images\"\n",
    "os.makedirs(destination_folder, exist_ok=True) # Ensure the folder exists\n",
    "\n",
    "print(\"Step 1: Downloading dataset to the local cache...\")\n",
    "\n",
    "# 2. Download the full dataset to the default cache location\n",
    "# Do NOT use the 'path' argument here.\n",
    "# The function will return the path to the unzipped files in the cache.\n",
    "source_path = kagglehub.dataset_download(\n",
    "    \"samuelcortinhas/cats-and-dogs-image-classification\"\n",
    ")\n",
    "\n",
    "print(f\"   > Download complete. Cached at: {source_path}\")\n",
    "print(\"\\nStep 2: Copying files to the 'images' folder...\")\n",
    "\n",
    "# 3. Copy the entire directory from the cache to your destination folder\n",
    "# shutil.copytree is perfect for copying a whole folder and its contents.\n",
    "# dirs_exist_ok=True prevents an error if you run the script a second time.\n",
    "shutil.copytree(source_path, destination_folder, dirs_exist_ok=True)\n",
    "\n",
    "print(f\"✅ Dataset successfully copied to: {os.path.abspath(destination_folder)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff282ebf-643d-4580-baaf-44cf62e0600f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3323c578-340b-40b1-8b40-05066bc78e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- UPDATED PATHS ---\n",
    "# This dataset has a different folder structure.\n",
    "train_dir = os.path.join( 'images', 'train')\n",
    "test_dir = os.path.join('images', 'test')\n",
    "\n",
    "# Verify that the paths exist\n",
    "if not os.path.exists(train_dir):\n",
    "    raise FileNotFoundError(f\"Training directory not found at: {train_dir}\")\n",
    "if not os.path.exists(test_dir):\n",
    "    raise FileNotFoundError(f\"Validation directory not found at: {test_dir}\")\n",
    "\n",
    "print(f\"Training data path: {train_dir}\")\n",
    "print(f\"Validation data path: {test_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b5994a-74d9-414f-a03e-a6ff2b1985cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================\n",
    "# 3. COUNT AND VISUALIZE DATA DISTRIBUTION\n",
    "# =======================================================\n",
    "print(\"\\n--- Analyzing Data Distribution ---\")\n",
    "try:\n",
    "    num_train_cats = len(os.listdir(os.path.join(train_dir, 'cats')))\n",
    "    num_train_dogs = len(os.listdir(os.path.join(train_dir, 'dogs')))\n",
    "    num_test_cats = len(os.listdir(os.path.join(test_dir, 'cats')))\n",
    "    num_test_dogs = len(os.listdir(os.path.join(test_dir, 'dogs')))\n",
    "\n",
    "    print(f\"Training set contains: {num_train_cats} cats and {num_train_dogs} dogs.\")\n",
    "    print(f\"Test set contains:     {num_test_cats} cats and {num_test_dogs} dogs.\")\n",
    "\n",
    "    labels = ['Train Cats', 'Train Dogs', 'Test Cats', 'Test Dogs']\n",
    "    counts = [num_train_cats, num_train_dogs, num_test_cats, num_test_dogs]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(labels, counts, color=['#ff9999', '#66b3ff', '#ffcc99', '#99ff99'])\n",
    "    plt.title('Image Count by Class and Set')\n",
    "    plt.ylabel('Number of Images')\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2.0, yval, int(yval), va='bottom', ha='center')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Could not find cat/dog subdirectories. Please check the dataset structure.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cc632b-4df1-4297-8b62-01b40a6fc861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================\n",
    "# 4. PREPARE, SCALE, AND OPTIMIZE DATASETS (Corrected)\n",
    "# =======================================================\n",
    "print(\"\\n--- Preparing, Scaling, and Optimizing Datasets ---\")\n",
    "\n",
    "image_size = (256, 256)\n",
    "batch_size = 32\n",
    "\n",
    "# Load the raw training data FIRST to get the class names\n",
    "raw_train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    validation_split=0.02,\n",
    "    subset='training',\n",
    "    seed=123,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "# NOW, grab the class_names attribute from the raw dataset\n",
    "class_names = raw_train_ds.class_names\n",
    "print(f\"✅ Class names captured: {class_names}\")\n",
    "\n",
    "# Load the other raw datasets\n",
    "raw_val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    validation_split=0.02,\n",
    "    subset='validation',\n",
    "    seed=123,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "raw_test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Define the scaling function and performance optimizer\n",
    "def scale_data(image, label):\n",
    "    return image / 255.0, label\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# THEN, apply the map, cache, and prefetch transformations\n",
    "train_ds = raw_train_ds.map(scale_data).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = raw_val_ds.map(scale_data).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = raw_test_ds.map(scale_data).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "print(\"✅ Datasets are scaled, cached, and ready for training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1ef0aa-0a55-459c-8aef-bc9d9cbe5d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================\n",
    "# 5. VISUALIZE A BATCH OF SCALED DATA\n",
    "# =======================================================\n",
    "print(\"\\n--- Displaying a Sample of Training Images ---\")\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Get one batch from the dataset iterator\n",
    "images, labels = next(iter(train_ds))\n",
    "\n",
    "for i in range(4):\n",
    "    ax = plt.subplot(2, 2, i + 1)\n",
    "    plt.imshow(images[i].numpy())\n",
    "    plt.title(class_names[int(labels[i])])\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44131af0-1d95-4394-9ff1-1fb0ff376289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================\n",
    "# 6. BUILD A MODEL WITH TRANSFER LEARNING\n",
    "# =======================================================\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "print(\"\\n--- Building Model with MobileNetV2 Base ---\")\n",
    "\n",
    "# 1. Define the input shape\n",
    "input_shape = (256, 256, 3)\n",
    "\n",
    "# 2. Load the pre-trained MobileNetV2 model as a base\n",
    "# We don't include the final classification layer (include_top=False)\n",
    "base_model = MobileNetV2(\n",
    "    input_shape=input_shape,\n",
    "    include_top=False, # We'll add our own classifier\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# 3. Freeze the base model\n",
    "# This prevents the pre-trained weights from being updated during training\n",
    "base_model.trainable = False\n",
    "\n",
    "# 4. Create the new model by adding our layers on top of the base\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(), # A layer to average the features\n",
    "    Dense(1, activation='sigmoid') # Our final binary classifier\n",
    "])\n",
    "\n",
    "# 5. Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), # Use a slightly lower learning rate\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979b6f8e-2b9b-496e-a8ef-ad0cccf186c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================\n",
    "# 7. TRAIN THE NEW MODEL\n",
    "# =======================================================\n",
    "print(\"\\\\n--- Starting New Model Training ---\")\n",
    "logdir = 'logs_mobilenet' # Use a new log directory\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=30, # 10 epochs is a good starting point for transfer learning\n",
    "    callbacks=[tensorboard_callback]\n",
    ")\n",
    "\n",
    "print(\"--- New Model Training Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063f0a50-2fbb-4977-8ee3-c6ace766b794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================\n",
    "# 8. PLOT LEARNING CURVES\n",
    "# =======================================================\n",
    "print(\"\\n--- Plotting Learning Curves ---\")\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b61e0c6b-f08e-4629-907a-b8d83f9ebc82",
   "metadata": {},
   "source": [
    "\n",
    "## What the Metrics Mean\n",
    "Precision: Of all the images the model predicted were dogs, what percentage were actually dogs? (A high precision means a low false positive rate).\n",
    "\n",
    "Recall: Of all the actual dog images in the dataset, what percentage did the model correctly identify? (A high recall means a low false negative rate).\n",
    "\n",
    "F1-Score: The harmonic mean of precision and recall. It provides a single, balanced measure of a model's performance.\n",
    "\n",
    "Confusion Matrix: A table that visualizes performance,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a65b5f-01f4-4f8a-a24d-7e9ddef79cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74216bac-7851-4866-9736-d5c865b2955d",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec38fa3-c528-4af4-bac3-059fd12c3829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================\n",
    "# 8. FINAL EVALUATION ON THE TEST SET\n",
    "# =======================================================\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "print(\"\\n--- Evaluating final model performance on the test set ---\")\n",
    "\n",
    "# Create empty lists to store all the true labels and predicted labels\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Iterate through the test_ds to get predictions for every image\n",
    "for images, labels in test_ds:\n",
    "    predictions = model.predict(images)\n",
    "    # Convert the sigmoid probabilities to binary predictions (0 or 1)\n",
    "    binary_predictions = (predictions > 0.5).astype(int).flatten()\n",
    "    \n",
    "    # Add the results for this batch to our lists\n",
    "    predicted_labels.extend(binary_predictions)\n",
    "    true_labels.extend(labels.numpy().astype(int))\n",
    "\n",
    "# Convert the lists into arrays for scikit-learn\n",
    "true_labels = np.array(true_labels)\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# --- Generate and Print Classification Report ---\n",
    "print(\"\\n--- Classification Report for Test Set ---\")\n",
    "# This report shows the final precision, recall, and F1-score.\n",
    "print(classification_report(true_labels, predicted_labels, target_names=class_names))\n",
    "\n",
    "\n",
    "# --- Generate and Plot Confusion Matrix ---\n",
    "print(\"\\n--- Generating Final Confusion Matrix Plot ---\")\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix for Test Set')\n",
    "plt.ylabel('Actual Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3c84df-2bce-4de9-8613-c1dce72bebba",
   "metadata": {},
   "source": [
    "# upload a photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f13c99-0f4c-4423-8db2-64992a4cb92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be5bb25-cd80-4a72-9448-ae1127a8ecd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This would be the last step after model.fit()\n",
    "model.save('cat_dog_classifier.keras')\n",
    "print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fc47ab-d58a-42c6-902d-a7d3bb9372c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the path to your saved model file\n",
    "model_path = 'cat_dog_classifier.keras'\n",
    "\n",
    "# Load the model\n",
    "loaded_model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Verify that the model has been loaded correctly by printing its summary\n",
    "print(\"✅ Model loaded successfully. Here is the model summary:\")\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09762e9f-f3dd-4e13-b6f8-74a2156c6171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================\n",
    "# 9. TEST WITH YOUR OWN IMAGE \n",
    "# =======================================================\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout\n",
    "from IPython.display import display, clear_output\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# --- Define a layout for bigger buttons ---\n",
    "button_layout = Layout(width='400px', height='80px')\n",
    "\n",
    "# --- Create the widgets using the new layout ---\n",
    "uploader = widgets.FileUpload(\n",
    "    accept='image/*',\n",
    "    multiple=False,\n",
    "    description='Upload Pet Image',\n",
    "    layout=button_layout\n",
    ")\n",
    "\n",
    "classify_button = widgets.Button(\n",
    "    description='Classify Image',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    icon='search',\n",
    "    layout=button_layout\n",
    ")\n",
    "\n",
    "output_area = widgets.Output()\n",
    "\n",
    "# --- Define the function that runs when the button is clicked ---\n",
    "def classify_image_on_click(b):\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        if not uploader.value:\n",
    "            print(\"Please upload an image first.\")\n",
    "            return\n",
    "            \n",
    "        print(\"Processing image...\")\n",
    "        try:\n",
    "            # CORRECTED LINE: Access the file dictionary from the tuple using its index [0]\n",
    "            uploaded_file = uploader.value[0] \n",
    "            content = uploaded_file['content']\n",
    "            \n",
    "            # 1. Preprocess the image\n",
    "            img = Image.open(io.BytesIO(content))\n",
    "            img_array = np.array(img)\n",
    "            img_tensor = tf.convert_to_tensor(img_array)[:, :, :3]\n",
    "\n",
    "            img_resized = tf.image.resize(img_tensor, [256, 256])\n",
    "            img_scaled = img_resized / 255.0\n",
    "            img_batch = tf.expand_dims(img_scaled, 0)\n",
    "\n",
    "            # 2. Make a prediction\n",
    "            print(\"Model is predicting...\")\n",
    "            prediction_score = model.predict(img_batch)[0][0]\n",
    "            \n",
    "            # 3. Interpret and display the result\n",
    "            if prediction_score < 0.5:\n",
    "                predicted_class = class_names[0]\n",
    "                confidence = (1 - prediction_score) * 100\n",
    "            else:\n",
    "                predicted_class = class_names[1]\n",
    "                confidence = prediction_score * 100\n",
    "\n",
    "            print(f\"✅ Prediction: {predicted_class}\")\n",
    "            \n",
    "            plt.figure(figsize=(6,6))\n",
    "            plt.imshow(img_array)\n",
    "            plt.title(f\"Model Prediction: {predicted_class} ({confidence:.1f}% confident)\")\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "# --- Link the button's on_click event to our function ---\n",
    "classify_button.on_click(classify_image_on_click)\n",
    "\n",
    "# --- Display all the widgets ---\n",
    "print(\"Ready to classify. Upload an image, then click the button.\")\n",
    "display(uploader, classify_button, output_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5d3458-ce6f-468a-803b-63f778e4d556",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cats-vs-dogs)",
   "language": "python",
   "name": "cats-vs-dogs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
